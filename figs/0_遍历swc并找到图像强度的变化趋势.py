import os.path

import pandas as pd
import numpy as np
import tifffile
import matplotlib.pyplot as plt
from skimage.transform import resize
from tqdm import tqdm
import joblib
import seaborn as sns
import sys
import networkx as nx
import tempfile
import shutil
import subprocess
import cv2
from scipy.fftpack import fftn, fftshift
from brokenaxes import brokenaxes

v3d_path = r"/home/kfchen/Vaa3D-x.1.1.4_Ubuntu/Vaa3D-x"
mouse_neuron_info_file = "/data/kfchen/trace_ws/img_noise_test/seu1876/41467_2024_54745_MOESM3_ESM.xlsx"
mouse_neuron_info_df = pd.read_excel(mouse_neuron_info_file)
neuron_info_df = pd.read_csv("/data/kfchen/nnUNet/nnUNet_results/Dataset169_hb_10k/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/ptls10/norm_result/Human_SingleCell_TrackingTable_20240712.csv", encoding='gbk')
N_JOBS = 20
sys.setrecursionlimit(50000)

# è¯»å–SWCæ–‡ä»¶åˆ°pandas DataFrame
def read_swc(file_path, xy_resolution):
    # è¯»å–SWCæ–‡ä»¶
    df = pd.read_csv(file_path, sep=' ', header=None, comment='#',
                     names=['id', 'type', 'x', 'y', 'z', 'radius', 'parent'],
                     dtype={'id': int, 'type': int, 'x': float, 'y': float, 'z': float, 'radius': float, 'parent': int})
    df['x'] = df['x'] * xy_resolution / 1000
    df['y'] = df['y'] * xy_resolution / 1000
    return df

def read_eswc(file_path, xy_resolution):
    ##n,type,x,y,z,radius,parent,seg_id,level,mode,timestamp,teraflyindex,feature_value
    df = pd.read_csv(file_path, sep=' ', header=None, comment='#',
                     names=['id', 'type', 'x', 'y', 'z', 'radius', 'parent', 'seg_id', 'level', 'mode', 'timestamp', 'teraflyindex', 'feature_value'],
                     dtype={'id': int, 'type': int, 'x': float, 'y': float, 'z': float, 'radius': float, 'parent': int,
                            'seg_id': int, 'level': int, 'mode': int, 'timestamp': int, 'teraflyindex': int, 'feature_value': float})
    df['x'] = df['x'] * xy_resolution / 1000
    df['y'] = df['y'] * xy_resolution / 1000
    return df

# ä»somaèŠ‚ç‚¹å¼€å§‹éå†æ‰€æœ‰èŠ‚ç‚¹
def traverse_from_soma(swc_df, img):
    # æ‰¾åˆ°somaèŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯type == 1ï¼‰
    soma_node = swc_df[swc_df['type'] == 1].iloc[0]
    soma_id = soma_node['id']

    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨ä»æ¯ä¸ªèŠ‚ç‚¹åˆ°å…¶å­èŠ‚ç‚¹çš„è¿æ¥å…³ç³»
    tree = {}
    for _, row in swc_df.iterrows():
        if row['parent'] != -1:  # parent == -1è¡¨ç¤ºæ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼ˆæ ¹èŠ‚ç‚¹ï¼‰
            if row['parent'] not in tree:
                tree[row['parent']] = []
            tree[row['parent']].append(row['id'])

    # å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹åˆ°somaçš„è·¯å¾„è·ç¦»å’Œç›´çº¿è·ç¦»
    distance_to_soma = {soma_id: 0.0}  # somaåˆ°è‡ªå·±çš„è·ç¦»ä¸º0
    straight_line_distance = {soma_id: 0.0}  # somaåˆ°è‡ªå·±çš„ç›´çº¿è·ç¦»ä¸º0
    img_value = {soma_id: img[int(soma_node['z']), int(soma_node['y']), int(soma_node['x'])]}
    visited = set()  # è®°å½•å·²è®¿é—®çš„èŠ‚ç‚¹

    # è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æ¬§æ°è·ç¦»
    def euclidean_distance(p1, p2):
        return np.sqrt((p1['x'] - p2['x']) ** 2 + (p1['y'] - p2['y']) ** 2 + (p1['z'] - p2['z']) ** 2)

    # æ·±åº¦ä¼˜å…ˆæœç´¢DFSï¼Œä»somaå¼€å§‹éå†
    def dfs(node_id, current_distance, current_straight_distance):
        # éå†è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
        if node_id in visited:
            return

        visited.add(node_id)

        # è·å–å½“å‰èŠ‚ç‚¹çš„ä¿¡æ¯
        current_node = swc_df[swc_df['id'] == node_id].iloc[0]

        # è®°å½•å½“å‰èŠ‚ç‚¹åˆ°somaçš„è·¯å¾„è·ç¦»ï¼ˆè·¯å¾„æ€»å’Œï¼‰å’Œç›´çº¿è·ç¦»
        distance_to_soma[node_id] = current_distance
        straight_line_distance[node_id] = current_straight_distance
        z, y, x = int(current_node['z']), int(current_node['y']), int(current_node['x'])
        z, y, x = min(max(z, 0), img.shape[0]-1), min(max(y, 0), img.shape[1]-1), min(max(x, 0), img.shape[2]-1)
        img_value[node_id] = img[z, y, x]

        # éå†æ‰€æœ‰å­èŠ‚ç‚¹
        if node_id in tree:
            for child_id in tree[node_id]:
                # è®¡ç®—ä»å½“å‰èŠ‚ç‚¹åˆ°å­èŠ‚ç‚¹çš„ç›´çº¿è·ç¦»
                child_node = swc_df[swc_df['id'] == child_id].iloc[0]
                edge_distance = euclidean_distance(current_node, child_node)
                # é€’å½’è°ƒç”¨DFSï¼Œç´¯åŠ è·¯å¾„è·ç¦»å’Œç›´çº¿è·ç¦»
                dfs(child_id, current_distance + edge_distance, euclidean_distance(soma_node, child_node))

    # ä»somaèŠ‚ç‚¹å¼€å§‹éå†
    dfs(soma_id, 0.0, 0.0)

    swc_df['path_dist'] = np.nan
    swc_df['euclidean_dist'] = np.nan
    swc_df['image_intensity'] = np.nan
    for node_id in distance_to_soma:
        swc_df.loc[swc_df['id'] == node_id, 'path_dist'] = distance_to_soma[node_id]
        swc_df.loc[swc_df['id'] == node_id, 'euclidean_dist'] = straight_line_distance[node_id]
        swc_df.loc[swc_df['id'] == node_id, 'image_intensity'] = img_value[node_id]

    # return distance_to_soma, straight_line_distance, img_value
    return swc_df

def traverse_from_soma_eswc(swc_df):
    # æ‰¾åˆ°somaèŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯type == 1ï¼‰
    soma_node = swc_df[swc_df['type'] == 1].iloc[0]
    soma_id = soma_node['id']

    # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨ä»æ¯ä¸ªèŠ‚ç‚¹åˆ°å…¶å­èŠ‚ç‚¹çš„è¿æ¥å…³ç³»
    tree = {}
    for _, row in swc_df.iterrows():
        if row['parent'] != -1:  # parent == -1è¡¨ç¤ºæ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼ˆæ ¹èŠ‚ç‚¹ï¼‰
            if row['parent'] not in tree:
                tree[row['parent']] = []
            tree[row['parent']].append(row['id'])

    # å­˜å‚¨æ¯ä¸ªèŠ‚ç‚¹åˆ°somaçš„è·¯å¾„è·ç¦»å’Œç›´çº¿è·ç¦»
    distance_to_soma = {soma_id: 0.0}  # somaåˆ°è‡ªå·±çš„è·ç¦»ä¸º0
    straight_line_distance = {soma_id: 0.0}  # somaåˆ°è‡ªå·±çš„ç›´çº¿è·ç¦»ä¸º0
    img_value = {soma_id: soma_node['level']}
    visited = set()  # è®°å½•å·²è®¿é—®çš„èŠ‚ç‚¹

    # è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æ¬§æ°è·ç¦»
    def euclidean_distance(p1, p2):
        return np.sqrt((p1['x'] - p2['x']) ** 2 + (p1['y'] - p2['y']) ** 2 + (p1['z'] - p2['z']) ** 2)

    # æ·±åº¦ä¼˜å…ˆæœç´¢DFSï¼Œä»somaå¼€å§‹éå†
    # def dfs(node_id, current_distance, current_straight_distance):
    #     # éå†è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
    #     if node_id in visited:
    #         return
    #
    #     visited.add(node_id)
    #
    #     # è·å–å½“å‰èŠ‚ç‚¹çš„ä¿¡æ¯
    #     current_node = swc_df[swc_df['id'] == node_id].iloc[0]
    #
    #     # è®°å½•å½“å‰èŠ‚ç‚¹åˆ°somaçš„è·¯å¾„è·ç¦»ï¼ˆè·¯å¾„æ€»å’Œï¼‰å’Œç›´çº¿è·ç¦»
    #     distance_to_soma[node_id] = current_distance
    #     straight_line_distance[node_id] = current_straight_distance
    #     img_value[node_id] = current_node['level']
    #
    #     # éå†æ‰€æœ‰å­èŠ‚ç‚¹
    #     if node_id in tree:
    #         for child_id in tree[node_id]:
    #             # è®¡ç®—ä»å½“å‰èŠ‚ç‚¹åˆ°å­èŠ‚ç‚¹çš„ç›´çº¿è·ç¦»
    #             child_node = swc_df[swc_df['id'] == child_id].iloc[0]
    #             edge_distance = euclidean_distance(current_node, child_node)
    #             # é€’å½’è°ƒç”¨DFSï¼Œç´¯åŠ è·¯å¾„è·ç¦»å’Œç›´çº¿è·ç¦»
    #             dfs(child_id, current_distance + edge_distance, euclidean_distance(soma_node, child_node))
    #
    # # ä»somaèŠ‚ç‚¹å¼€å§‹éå†
    # dfs(soma_id, 0.0, 0.0)
    def dfs_optimized(soma_id):
        # é€šè¿‡å°†swc_dfè½¬åŒ–ä¸ºå­—å…¸ï¼Œæé«˜æŸ¥æ‰¾æ•ˆç‡
        node_info = {row['id']: row for _, row in swc_df.iterrows()}

        # åˆå§‹åŒ–æ ˆä»¥æ¨¡æ‹Ÿé€’å½’
        stack = [(soma_id, 0.0, 0.0)]  # (å½“å‰èŠ‚ç‚¹id, å½“å‰è·¯å¾„è·ç¦», å½“å‰ç›´çº¿è·ç¦»)

        # ç”¨ä¸€ä¸ªé›†åˆè®°å½•è®¿é—®çš„èŠ‚ç‚¹ï¼Œé¿å…é‡å¤è®¿é—®
        visited = set()

        while stack:
            node_id, current_distance, current_straight_distance = stack.pop()

            # å¦‚æœèŠ‚ç‚¹å·²ç»è®¿é—®è¿‡ï¼Œè·³è¿‡
            if node_id in visited:
                continue

            visited.add(node_id)

            # è·å–å½“å‰èŠ‚ç‚¹çš„ä¿¡æ¯
            current_node = node_info[node_id]

            # è®°å½•å½“å‰èŠ‚ç‚¹åˆ°somaçš„è·¯å¾„è·ç¦»ï¼ˆè·¯å¾„æ€»å’Œï¼‰å’Œç›´çº¿è·ç¦»
            distance_to_soma[node_id] = current_distance
            straight_line_distance[node_id] = current_straight_distance
            img_value[node_id] = current_node['level']

            # éå†æ‰€æœ‰å­èŠ‚ç‚¹
            if node_id in tree:
                for child_id in tree[node_id]:
                    # è·å–å­èŠ‚ç‚¹ä¿¡æ¯
                    child_node = node_info[child_id]
                    # è®¡ç®—å½“å‰èŠ‚ç‚¹åˆ°å­èŠ‚ç‚¹çš„ç›´çº¿è·ç¦»
                    edge_distance = euclidean_distance(current_node, child_node)
                    # å°†å­èŠ‚ç‚¹å’Œæ–°è®¡ç®—çš„è·ç¦»å‹å…¥æ ˆä¸­
                    stack.append(
                        (child_id, current_distance + edge_distance, euclidean_distance(soma_node, child_node)))

    # ä»somaèŠ‚ç‚¹å¼€å§‹éå†
    dfs_optimized(soma_id)

    # swc_df['path_dist'] = np.nan
    # swc_df['euclidean_dist'] = np.nan
    # swc_df['image_intensity'] = np.nan
    swc_df.loc[:, 'path_dist'] = np.nan
    swc_df.loc[:, 'euclidean_dist'] = np.nan
    swc_df.loc[:, 'image_intensity'] = np.nan
    for node_id in distance_to_soma:
        swc_df.loc[swc_df['id'] == node_id, 'path_dist'] = distance_to_soma[node_id]
        swc_df.loc[swc_df['id'] == node_id, 'euclidean_dist'] = straight_line_distance[node_id]
        swc_df.loc[swc_df['id'] == node_id, 'image_intensity'] = img_value[node_id]
    # swc_df['path_dist'] = swc_df['id'].map(distance_to_soma)
    # swc_df['euclidean_dist'] = swc_df['id'].map(straight_line_distance)
    # swc_df['image_intensity'] = swc_df['id'].map(img_value)

    # return distance_to_soma, straight_line_distance, img_value
    return swc_df

def plot_histogram(df):
    plt.figure(figsize=(10, 6))
    plt.scatter(df['path_dist'], df['image_intensity'], alpha=0.5, c=df['image_intensity'], cmap='viridis')
    plt.xlabel('Path Distance to Soma')
    plt.ylabel('Image Intensity')
    plt.title('Path Distance to Soma vs Image Intensity')
    # plt.colorbar(label='Image Intensity')
    plt.show()
    plt.close()

def calc_dist_i_file(swc_file, img_file, neuron_info_df, save_dir="/data/kfchen/trace_ws/img_noise_test/extended_swc"):
    save_file = os.path.join(save_dir, os.path.basename(swc_file).replace('.swc', '.csv'))
    if os.path.exists(save_file):
        swc_df = pd.read_csv(save_file)
        return swc_df['path_dist'], swc_df['image_intensity']

    id = int(os.path.basename(swc_file).split('.')[0])
    xy_resolution = neuron_info_df.loc[neuron_info_df.iloc[:, 0] == id, 'xyæ‹æ‘„åˆ†è¾¨ç‡(*10e-3Î¼m/px)'].values[0]
    img = tifffile.imread(img_file).astype(np.float32)
    img = (img - img.min()) / (img.max() - img.min())
    img = resize(img, (img.shape[0], img.shape[1] * xy_resolution / 1000, img.shape[2] * xy_resolution / 1000), order=2)
    img = (img - img.min()) / (img.max() - img.min()) * 255
    # img = np.flip(img, axis=1)

    # è¯»å–SWCæ–‡ä»¶
    swc_df = read_swc(swc_file, xy_resolution)
    swc_df = traverse_from_soma(swc_df, img)
    swc_df.to_csv(save_file, index=False)

    return swc_df['path_dist'], swc_df['image_intensity']
    # plot_histogram(swc_df)

def calc_dist_i_file_v2(swc_file, img_file, save_file):
    if os.path.exists(save_file):
        swc_df = pd.read_csv(save_file)
        return swc_df['path_dist'], swc_df['image_intensity']

    img = tifffile.imread(img_file).astype(np.float32)
    img = (img - img.min()) / (img.max() - img.min()) * 255
    img = np.flip(img, axis=1)

    swc_df = pd.read_csv(swc_file, sep=' ', header=None, comment='#',
                     names=['id', 'type', 'x', 'y', 'z', 'radius', 'parent'],
                     dtype={'id': int, 'type': int, 'x': float, 'y': float, 'z': float, 'radius': float, 'parent': int})

    # mip = np.max(img, axis=0)
    # plt.imshow(mip)
    # plt.savefig(os.path.join("/data/kfchen/trace_ws/img_noise_test/temp_mip", os.path.basename(swc_file).replace('.swc', '_img.png')))
    # plt.close()
    # # cv2
    # for x, y, z in zip(swc_df['x'], swc_df['y'], swc_df['z']):
    #     cv2.circle(mip, (int(x), int(y)), 1, 255, -1)
    # plt.imshow(mip)
    # plt.savefig(os.path.join("/data/kfchen/trace_ws/img_noise_test/temp_mip", os.path.basename(swc_file).replace('.swc', '_swc.png')))
    # plt.close()
    # exit()

    try:
        swc_df = traverse_from_soma(swc_df, img)
    except:
        print(f"Error in {swc_file}")
        swc_df['path_dist'] = np.nan
        swc_df['image_intensity'] = np.nan

    swc_df.to_csv(save_file, index=False)

    return swc_df['path_dist'], swc_df['image_intensity']

def crop_box_from_soma(swc_file, lim):
    x_lim, y_lim, z_lim = lim
    df = pd.read_csv(swc_file, comment='#', sep=' ', index_col=0 ,
                     names=('id', 'type', 'x', 'y', 'z', 'r', 'pid'))
    soma = df[df.type == 1 & (df.pid == -1)]
    assert len(soma) == 1
    soma = soma.iloc[0]
    soma_x, soma_y, soma_z = soma[['x', 'y', 'z']]

    x_min, x_max = soma_x - x_lim/2, soma_x + x_lim/2
    y_min, y_max = soma_y - y_lim/2, soma_y + y_lim/2
    z_min, z_max = soma_z - z_lim/2, soma_z + z_lim/2
    df_crop = df[(df.x >= x_min) & (df.x <= x_max) &
                 (df.y >= y_min) & (df.y <= y_max) &
                 (df.z >= z_min) & (df.z <= z_max)]
    df_crop.x = df_crop.x - x_min
    df_crop.y = df_crop.y - y_min
    df_crop.z = df_crop.z - z_min
    return df_crop

def estimate_radius(img_file, swc_file, out_file):
    def v3d_get_radius(img_path, swc_path, out_path):
        with tempfile.TemporaryDirectory() as temp_dir:
            # è·å–æ–‡ä»¶å
            img_filename = os.path.basename(img_path).split('_')[0] + '.tif'
            swc_filename = os.path.basename(swc_path).split('_')[0] + '.swc'
            output_filename = os.path.basename(out_path).split('_')[0] + '.swc'

            # è®¾ç½®ç¼“å­˜æ–‡ä»¶è·¯å¾„
            img_cache_path = os.path.join(temp_dir, img_filename)
            swc_cache_path = os.path.join(temp_dir, swc_filename)
            out_cache_path = os.path.join(temp_dir, output_filename)

            # å°†æ–‡ä»¶å¤åˆ¶åˆ°ç¼“å­˜è·¯å¾„
            shutil.copy(img_path, img_cache_path)
            shutil.copy(swc_path, swc_cache_path)

            # è®¾ç½®å‘½ä»¤å­—ç¬¦ä¸²
            radius2d = 1
            cmd_str = f'xvfb-run -a -s "-screen 0 640x480x16" {v3d_path} -x neuron_radius -f neuron_radius -i {img_cache_path} {swc_cache_path} -o {out_cache_path} -p 40 {radius2d}'
            cmd_str = cmd_str.replace('(', '\(').replace(')', '\)')

            # æ‰§è¡Œå‘½ä»¤
            # print(f"Running command: {cmd_str}")
            subprocess.run(cmd_str, stdout=subprocess.DEVNULL, shell=True)

            # å°†ç»“æœä»ä¸´æ—¶è·¯å¾„å¤åˆ¶åˆ°å®é™…è¾“å‡ºè·¯å¾„
            shutil.copy(out_cache_path, out_path)

    def load_swc_to_undirected_graph(swc_file_path):
        """ä»SWCæ–‡ä»¶åŠ è½½æ•°æ®ï¼Œæ„å»ºæ— å‘å›¾ï¼Œå¹¶è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„parentä¿¡æ¯"""
        df = pd.read_csv(swc_file_path, delim_whitespace=True, comment='#', header=None,
                         names=['id', 'type', 'x', 'y', 'z', 'radius', 'parent'])
        G = nx.Graph()

        for _, row in df.iterrows():
            # æ·»åŠ èŠ‚ç‚¹ï¼ŒåŒæ—¶è®°å½•parentä¿¡æ¯
            G.add_node(row['id'], pos=(row['x'], row['y'], row['z']), radius=row['radius'], type=row['type'],
                       parent=row['parent'])
            if row['parent'] != -1:
                G.add_edge(row['parent'], row['id'])

        return G

    def find_nearest_node(G, target_pos):
        """ åœ¨å›¾ä¸­æ‰¾åˆ°ä¸ç»™å®šåæ ‡æœ€è¿‘çš„èŠ‚ç‚¹ """
        nearest_node = None
        min_distance = float('inf')

        for node in G.nodes(data=True):
            pos = node[1]['pos']
            distance = np.linalg.norm(np.array(pos) - np.array(target_pos))
            if distance < min_distance:
                nearest_node = node[0]
                min_distance = distance

        return nearest_node

    def export_to_swc_dfs(G, root_pos, output_filename):
        if(os.path.exists(output_filename)):
            os.remove(output_filename)

        start_node = find_nearest_node(G, root_pos)

        # è°ƒæ•´æ ¹èŠ‚ç‚¹
        potential_root = max(G.nodes, key=lambda x: G.degree(x))
        potential_root_degree = G.degree(potential_root)
        potential_root_list = [node for node in G.nodes if G.degree(node) == potential_root_degree]
        for node in potential_root_list:
            if G.degree(node) > 4 and len(potential_root_list) == 1:  # è¿™ä¸ªç‚¹çš„åº¦æ•°å¤§äº4
                start_node = node
            elif (nx.shortest_path_length(G, start_node, node) < 3):
                start_node = node
            elif (np.linalg.norm(np.array(G.nodes[node]['pos']) - np.array(root_pos)) < 10):
                start_node = node

        # æ‰“å¼€æ–‡ä»¶è¿›è¡Œå†™å…¥
        with open(output_filename, 'w') as f:
            # å†™å…¥SWCæ–‡ä»¶çš„å¤´éƒ¨æ³¨é‡Š
            f.write("# SWC file generated from DFS traversal\n")
            f.write("# Columns: id type x y z radius parent\n")

            # ç”¨äºå­˜å‚¨èŠ‚ç‚¹çš„æ–°ç¼–å·å’Œè®¿é—®çŠ¶æ€
            new_id = 1
            visited = set()
            stack = [(start_node, -1)]  # (current_node, parent_id_in_new_swc)

            while stack:
                node, parent_id = stack.pop()
                if node not in visited:
                    visited.add(node)
                    node_data = G.nodes[node]
                    pos = node_data['pos']
                    radius = node_data['radius']
                    if (parent_id == -1):
                        node_type = 1
                    else:
                        node_type = 3

                    # å†™å…¥å½“å‰èŠ‚ç‚¹æ•°æ®
                    f.write(f"{new_id} {node_type} {pos[0]} {pos[1]} {pos[2]} {radius} {parent_id}\n")

                    # æ›´æ–°çˆ¶èŠ‚ç‚¹IDä¸ºå½“å‰èŠ‚ç‚¹çš„æ–°ID
                    current_parent_id = new_id
                    new_id += 1

                    # å°†æ‰€æœ‰æœªè®¿é—®çš„é‚»æ¥èŠ‚ç‚¹æ·»åŠ åˆ°æ ˆä¸­
                    for neighbor in G.neighbors(node):
                        if neighbor not in visited:
                            stack.append((neighbor, current_parent_id))

    def calc_node_dist(G, node1, node2):
        pos1 = np.array(G.nodes[node1]['pos'])
        pos2 = np.array(G.nodes[node2]['pos'])
        return np.linalg.norm(pos1 - pos2)

    def gaussian_smoothing_radius_tree(G, sigma=1.0):
        smoothed_values = {}
        soma_r = G.nodes[1]['radius']
        for node in G.nodes:
            neighbors = list(G.neighbors(node))
            weights = []
            values = []
            for neighbor in neighbors:
                distance = calc_node_dist(G, node, neighbor)
                weight = np.exp(- (distance ** 2) / (2 * sigma ** 2))
                weights.append(weight)
                values.append(G.nodes[neighbor]['radius'])
            # è‡ªèº«çš„æƒé‡
            self_weight = np.exp(0)
            total_weight = self_weight + sum(weights)
            weighted_sum = G.nodes[node]['radius'] * self_weight + sum(w * v for w, v in zip(weights, values))
            smoothed_values[node] = weighted_sum / total_weight
        nx.set_node_attributes(G, smoothed_values, 'radius')
        G.nodes[1]['radius'] = soma_r
        return G

    def smoothing_swc_file(swc_file_path, output_filename):
        G = load_swc_to_undirected_graph(swc_file_path)
        G = gaussian_smoothing_radius_tree(G)
        root_pos = G.nodes[1]['pos']
        # print(root_pos)
        export_to_swc_dfs(G, root_pos, output_filename)

    if(os.path.exists(out_file)):
        return
    try:
        v3d_get_radius(img_file, swc_file, out_file)
        smoothing_swc_file(out_file, out_file)
    except:
        print(f"Error in {swc_file}")

def swc_to_img(img_file, swc_file, mask_file):
    img = tifffile.imread(img_file)
    cmd_str = f'xvfb-run -a -s "-screen 0 640x480x16" {v3d_path} -x swc_to_maskimage_sphere_unit -f swc_to_maskimage -i {swc_file} ' \
              f'-p {img.shape[2]} {img.shape[1]} {img.shape[0]} -o {mask_file}'
    cmd_str = cmd_str.replace('(', '\(').replace(')', '\)')
    # print(cmd_str)
    subprocess.run(cmd_str, stdout=subprocess.DEVNULL, shell=True)
    mask = tifffile.imread(mask_file)
    mask = mask.astype(np.float32)
    mask = np.flip(mask, axis=1)
    mask = (mask - mask.min()) / (mask.max() - mask.min()) * 255
    tifffile.imwrite(mask_file, mask.astype('uint8'))

def compute_forground_info(img_file, mask_file, save_file):
    if(os.path.exists(save_file)):
        return np.load(save_file)
    # è¯»å–å›¾åƒå’Œæ©è†œ
    img = tifffile.imread(img_file)
    mask = tifffile.imread(mask_file)
    mask = np.where(mask > 0, 255, 0)
    img = img.astype(np.float32)
    img = (img - img.min()) / (img.max() - img.min()) # * 255

    # ç¡®ä¿æ©è†œæ˜¯äºŒå€¼çš„ï¼ˆå‰æ™¯ä¸º1ï¼ŒèƒŒæ™¯ä¸º0ï¼‰
    foreground_mask = (mask == 255)
    background_mask = (mask == 0)

    # è®¡ç®—å‰æ™¯å’ŒèƒŒæ™¯çš„å¼ºåº¦ä¸­ä½æ•°
    foreground_intensities = img[foreground_mask]
    background_intensities = img[background_mask]

    foreground_median = np.median(foreground_intensities) if foreground_intensities.size > 0 else None
    background_median = np.median(background_intensities) if background_intensities.size > 0 else None
    foreground_mean = np.mean(foreground_intensities) if foreground_intensities.size > 0 else None
    background_mean = np.mean(background_intensities) if background_intensities.size > 0 else None
    contrast = (foreground_mean - background_mean) / np.sqrt(foreground_intensities.var() + background_intensities.var())
    contrast_guo = foreground_median - background_median
    foreground_homogeneity_entropy = -np.sum(foreground_intensities * np.log(foreground_intensities + 1e-6)) / (foreground_intensities.size + 1e-6)
    background_homogeneity_entropy = -np.sum(background_intensities * np.log(background_intensities + 1e-6)) / (background_intensities.size + 1e-6)
    foreground_uniformity = -np.sum(foreground_intensities * foreground_intensities) / (foreground_intensities.size + 1e-6)
    background_uniformity = -np.sum(background_intensities * background_intensities) / (background_intensities.size + 1e-6)

    result = {
        'foreground_median': foreground_median,
        'background_median': background_median,
        'foreground_mean': foreground_mean,
        'background_mean': background_mean,
        'contrast': contrast,
        'contrast_guo': contrast_guo,
        'foreground_homogeneity_entropy': foreground_homogeneity_entropy,
        'background_homogeneity_entropy': background_homogeneity_entropy,
        'foreground_uniformity': foreground_uniformity,
        'background_uniformity': background_uniformity
    }

    np.save(save_file, result)
    return result

def prepare_proposed():
    img_dir = "/data/kfchen/trace_ws/to_gu/img"
    swc_dir = "/data/kfchen/trace_ws/paper_auto_human_neuron_recon/swc_label/2_flip_after_sort"
    swc_files = [f for f in os.listdir(swc_dir) if f.endswith('.swc')]

    # resize
    target_img_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_img_1um"
    target_swc_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_swc_1um"

    def current_resize(img_file, swc_file, target_img_file, target_swc_file):
        id = int(os.path.basename(swc_file).split('.')[0])
        xy_resolution = neuron_info_df.loc[neuron_info_df.iloc[:, 0] == id, 'xyæ‹æ‘„åˆ†è¾¨ç‡(*10e-3Î¼m/px)'].values[0]
        xy_resolution = xy_resolution / 1000

        if(not os.path.exists(target_img_file)):
            img = tifffile.imread(img_file).astype(np.float32)
            img = (img - img.min()) / (img.max() - img.min())
            img = resize(img, (img.shape[0], img.shape[1] * xy_resolution, img.shape[2] * xy_resolution), order=2)
            img = (img - img.min()) / (img.max() - img.min()) * 255
            tifffile.imwrite(target_img_file, img.astype('uint8'))

        if(not os.path.exists(target_swc_file)):
            swc = pd.read_csv(swc_file, sep=' ', header=None, comment='#',
                              names=['id', 'type', 'x', 'y', 'z', 'radius', 'parent'],
                              dtype={'id': int, 'type': int, 'x': float, 'y': float, 'z': float, 'radius': float,
                                     'parent': int})
            swc.x = swc.x * xy_resolution
            swc.y = swc.y * xy_resolution
            swc.to_csv(target_swc_file, sep=' ', header=False, index=False)

    swc_files = [f for f in os.listdir(swc_dir) if f.endswith('.swc')]
    # if(os.path.exists(target_img_dir) == False):
    #     os.makedirs(target_img_dir, exist_ok=True)
    #     os.makedirs(target_swc_dir, exist_ok=True)
    #     joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_resize)(os.path.join(img_dir, swc_file.replace('.swc', '.tif')),
    #                                                               os.path.join(swc_dir, swc_file),
    #                                                               os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
    #                                                               os.path.join(target_swc_dir, swc_file)) for swc_file in tqdm(swc_files))

    swc_with_radius_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_swc_1um_with_radius"
    if(os.path.exists(swc_with_radius_dir) == False):
        os.makedirs(swc_with_radius_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(estimate_radius)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                   os.path.join(target_swc_dir, swc_file),
                                                                   os.path.join(swc_with_radius_dir, swc_file)) for swc_file in tqdm(swc_files))

    mask_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_mask_1um"
    if(os.path.exists(mask_dir) == False):
        os.makedirs(mask_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(swc_to_img)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                              os.path.join(swc_with_radius_dir, swc_file),
                                                              os.path.join(mask_dir, swc_file.replace('.swc', '.tif'))) for swc_file in tqdm(swc_files))
    # return
    ex_swc_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/extended_swc"
    if(os.path.exists(ex_swc_dir) == False):
        os.makedirs(ex_swc_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(calc_dist_i_file_v2)(os.path.join(swc_with_radius_dir, swc_file),
                                                                      os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                      os.path.join(ex_swc_dir, swc_file.replace('.swc', '.csv'))) for swc_file in tqdm(swc_files))

    foreground_info_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/foreground_info"
    if(os.path.exists(foreground_info_dir) == False):
        os.makedirs(foreground_info_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(compute_forground_info)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                              os.path.join(mask_dir, swc_file.replace('.swc', '.tif')),
                                                                              os.path.join(foreground_info_dir, swc_file.replace('.swc', '.npy'))) for swc_file in tqdm(swc_files))



def prepare_seu1876(crop_lim=(512, 512, 512)):
    # source_swc_dir = "/data/kfchen/trace_ws/quality_control_test/mouse/seu1876/raw"
    # target_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/" + f"cropped_box_swc_{crop_lim[0]}_{crop_lim[1]}_{crop_lim[2]}"
    #
    # if(os.path.exists(target_swc_dir) == False):
    #     os.makedirs(target_swc_dir, exist_ok=True)
    #     swc_files = [f for f in os.listdir(source_swc_dir) if f.endswith('.swc')]
    #
    #     def current_task(swc_file, source_swc_dir, target_swc_dir, crop_lim):
    #         df = crop_box_from_soma(os.path.join(source_swc_dir, swc_file), crop_lim)
    #         df.to_csv(os.path.join(target_swc_dir, swc_file), sep=' ', header=False)
    #     # for swc_file in swc_files:
    #     #     df = crop_box_from_soma(os.path.join(source_swc_dir, swc_file), crop_lim)
    #     #     df.to_csv(os.path.join(target_swc_dir, swc_file), sep=' ', header=False)
    #     joblib.Parallel(n_jobs=10)(joblib.delayed(current_task)(swc_file, source_swc_dir, target_swc_dir, crop_lim) for swc_file in tqdm(swc_files))

    profile_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/profiled_final"
    # target_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/" + f"cropped_box_swc_{crop_lim[0]}_{crop_lim[1]}_{crop_lim[2]}"
    extended_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/extended_swc_from_eswc"
    os.makedirs(extended_swc_dir, exist_ok=True)
    mouse_neuron_info_file = "/data/kfchen/trace_ws/img_noise_test/seu1876/41467_2024_54745_MOESM3_ESM.xlsx"
    mouse_neuron_info_df = pd.read_excel(mouse_neuron_info_file)
    fail_list = []

    eswc_files = [f for f in os.listdir(profile_swc_dir) if f.endswith('.eswc')]

    def current_task(eswc_file, profile_swc_dir, extended_swc_dir, crop_lim, mouse_neuron_info_df):
        image_id = eswc_file.split('_')[0]
        if(image_id == 'pre'):
            image_id = eswc_file.split('_')[1]
        xy_resolution = mouse_neuron_info_df.loc[mouse_neuron_info_df['Image ID'] == int(image_id), 'Resolution_XY (ğœ‡ğ‘š/voxel)'].values[0]
        target_file = os.path.join(extended_swc_dir, eswc_file.replace('.eswc', '.csv'))
        if os.path.exists(target_file):
            return
        df = read_eswc(os.path.join(profile_swc_dir, eswc_file), float(xy_resolution)*1000)
        soma = df[df.type == 1 & (df.parent == -1)]
        assert len(soma) == 1
        soma = soma.iloc[0]
        soma_x, soma_y, soma_z = soma[['x', 'y', 'z']]
        x_min, x_max = soma_x - crop_lim[0]/2, soma_x + crop_lim[0]/2
        y_min, y_max = soma_y - crop_lim[1]/2, soma_y + crop_lim[1]/2
        z_min, z_max = soma_z - crop_lim[2]/2, soma_z + crop_lim[2]/2
        df_crop = df[(df.x >= x_min) & (df.x <= x_max) &
                     (df.y >= y_min) & (df.y <= y_max) &
                     (df.z >= z_min) & (df.z <= z_max)]
        df_crop = traverse_from_soma_eswc(df_crop)
        df_crop.to_csv(target_file, index=False)

    # print(len(eswc_files))
    for eswc_file in eswc_files:
        image_id = eswc_file.split('_')[0]
        if(image_id == 'pre'):
            image_id = eswc_file.split('_')[1]
        # print(image_id)
        try:
            xy_resolution = mouse_neuron_info_df.loc[mouse_neuron_info_df['Image ID'] == int(image_id), 'Resolution_XY (ğœ‡ğ‘š/voxel)'].values[0]
        except:
            fail_list.append(eswc_file)

    # print(len(fail_list), len(eswc_files))
    eswc_files = [f for f in eswc_files if f not in fail_list]

    joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_task)(eswc_file, profile_swc_dir, extended_swc_dir, crop_lim, mouse_neuron_info_df) for eswc_file in tqdm(eswc_files))
    # for eswc_file in eswc_files:
    #     current_task(eswc_file, profile_swc_dir, extended_swc_dir, crop_lim, mouse_neuron_info_df)


def prepare_seu1876_new():
    # estimate_radius
    target_img_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/cropped_img_1um"
    target_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/cropped_swc_1um"

    swc_files = [f for f in os.listdir(target_swc_dir) if f.endswith('.swc')]
    swc_with_radius_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/cropped_swc_1um_with_radius"
    if(os.path.exists(swc_with_radius_dir) == False):
        os.makedirs(swc_with_radius_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(estimate_radius)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                   os.path.join(target_swc_dir, swc_file),
                                                                   os.path.join(swc_with_radius_dir, swc_file)) for swc_file in tqdm(swc_files))
    mask_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/cropped_mask_1um"
    if(os.path.exists(mask_dir) == False):
        os.makedirs(mask_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(swc_to_img)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                              os.path.join(swc_with_radius_dir, swc_file),
                                                              os.path.join(mask_dir, swc_file.replace('.swc', '.tif'))) for swc_file in tqdm(swc_files))
    # return
    # calc_dist_i_file_v2
    ex_human_swc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/extended_swc"
    # if(os.path.exists(ex_human_swc_dir) == False):
    os.makedirs(ex_human_swc_dir, exist_ok=True)
#     # for swc_file in tqdm(swc_files):
#     #     calc_dist_i_file_v2(os.path.join(target_swc_dir, swc_file),
#     #                         os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
#     #                         os.path.join(ex_human_swc_dir, swc_file.replace('.swc', '.csv')))
    joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(calc_dist_i_file_v2)(os.path.join(target_swc_dir, swc_file),
                                                                os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                os.path.join(ex_human_swc_dir, swc_file.replace('.swc', '.csv'))) for swc_file in tqdm(swc_files))

    foreground_info_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/foreground_info"
    if(os.path.exists(foreground_info_dir) == False):
        os.makedirs(foreground_info_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(compute_forground_info)(os.path.join(target_img_dir, swc_file.replace('.swc', '.tif')),
                                                                              os.path.join(mask_dir, swc_file.replace('.swc', '.tif')),
                                                                              os.path.join(foreground_info_dir, swc_file.replace('.swc', '.npy'))) for swc_file in tqdm(swc_files))
def plt_fig1():
    ex_human_swc_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/extended_swc"
    ex_mouse_eswc_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/extended_swc_from_eswc"
    human_files = [f for f in os.listdir(ex_human_swc_dir) if f.endswith('.csv')]
    mouse_files = [f for f in os.listdir(ex_mouse_eswc_dir) if f.endswith('.csv')]

    path_dists = [[], []]
    image_intensities = [[], []]
    for human_file in human_files:
        df = pd.read_csv(os.path.join(ex_human_swc_dir, human_file))
        current_path_dist, current_image_intensity = df['path_dist'], df['image_intensity']
        current_path_dist = [int(i) for i in current_path_dist]
        current_image_intensity = (current_image_intensity - current_image_intensity.min()) / (
                    current_image_intensity.max() - current_image_intensity.min()) * 255
        path_dists[0].extend(current_path_dist)
        image_intensities[0].extend(current_image_intensity)

    for mouse_file in mouse_files:
        df = pd.read_csv(os.path.join(ex_mouse_eswc_dir, mouse_file))[['type', 'path_dist', 'image_intensity']]
        df = df[df['type'] != 2]
        df = df.dropna()

        current_path_dist, current_image_intensity = df['path_dist'], df['image_intensity']
        current_path_dist = [int(i) for i in current_path_dist]
        current_image_intensity = (current_image_intensity - current_image_intensity.min()) / (
                    current_image_intensity.max() - current_image_intensity.min()) * 255
        if (len(current_image_intensity) == 0 or current_image_intensity[0] < 255 * 0.5):
            continue
        path_dists[1].extend(current_path_dist)
        image_intensities[1].extend(current_image_intensity)
    print(len(path_dists[0]), len(path_dists[1]))

    # hist
    # è®¾ç½®æ¸…æ™°åº¦
    plt.rcParams['figure.dpi'] = 300
    set2_colors = plt.cm.get_cmap('Set2').colors
    plt.figure(figsize=(4, 3))
    df = pd.DataFrame({
        'path_dist': path_dists[0],
        'image_intensity': image_intensities[0]
    })
    human_average_intensities = df.groupby('path_dist')['image_intensity'].mean().reset_index()
    df = pd.DataFrame({
        'path_dist': path_dists[1],
        'image_intensity': image_intensities[1]
    })
    mouse_average_intensities = df.groupby('path_dist')['image_intensity'].mean().reset_index()
    # plt.scatter(human_average_intensities['path_dist'], human_average_intensities['image_intensity'], alpha=0.5, color='red')
    # plt.scatter(mouse_average_intensities['path_dist'], mouse_average_intensities['image_intensity'], alpha=0.5, color='blue')
    # æŠ˜çº¿å›¾
    # plt.plot(human_average_intensities['path_dist'], human_average_intensities['image_intensity'], color='darkorange')
    # plt.plot(mouse_average_intensities['path_dist'], mouse_average_intensities['image_intensity'], color='skyblue')
    # æ‹Ÿåˆæ›²çº¿

    # def exp_decay(x, A, B, C):
    #     return A * np.exp(-B * x) + C
    #
    #
    # # æ‹Ÿåˆäººç±»æ•°æ®
    # human_x = human_average_intensities['path_dist']
    # human_y = human_average_intensities['image_intensity']
    # params_human, _ = curve_fit(exp_decay, human_x, human_y, p0=[1, 0.1, 0])  # åˆå§‹çŒœæµ‹å€¼
    #
    # # æ‹Ÿåˆå°é¼ æ•°æ®
    # mouse_x = mouse_average_intensities['path_dist']
    # mouse_y = mouse_average_intensities['image_intensity']
    # params_mouse, _ = curve_fit(exp_decay, mouse_x, mouse_y, p0=[1, 0.1, 0])  # åˆå§‹çŒœæµ‹å€¼
    #
    # human_fit_y = exp_decay(human_x, *params_human)
    # plt.plot(human_x, human_fit_y, label="Human Fit", color='darkorange', linewidth=2)
    #
    # # ç»˜åˆ¶å°é¼ æ‹Ÿåˆæ›²çº¿
    # mouse_fit_y = exp_decay(mouse_x, *params_mouse)
    # plt.plot(mouse_x, mouse_fit_y, label="Mouse Fit", color='skyblue', linewidth=2)

    # æŠ˜çº¿
    plt.plot(human_average_intensities['path_dist'], human_average_intensities['image_intensity'], color=set2_colors[0])
    plt.plot(mouse_average_intensities['path_dist'], mouse_average_intensities['image_intensity'], color=set2_colors[1])

    plt.xlim(0, 500)
    plt.ylim(0, 255)

    # plt.scatter(average_intensities['path_dist'], average_intensities['image_intensity'], alpha=0.5, c=average_intensities['image_intensity'], cmap='viridis')
    # kde
    # sns.kdeplot(x=path_dists, y=image_intensities, cmap='viridis', shade=True, cbar=True)

    plt.xlabel('Path dist. to soma', fontsize=15)
    plt.ylabel('Voxel value', fontsize=15)
    # tick
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    # plt.title('Path Distance to Soma vs Image Intensity')
    # legend
    plt.legend(['Human', 'Mouse'], fontsize=12, frameon=False)
    plt.tight_layout()
    # plt.colorbar(label='Image Intensity')
    plt.savefig("/data/kfchen/trace_ws/img_noise_test/Path_Distance_to_Soma_vs_Image_Intensity.png")
    plt.close()

    # plt.scatter(path_dists, image_intensities, alpha=0.5, c=image_intensities, cmap='viridis')
    # æ‹Ÿåˆæ›²çº¿
    # z = np.polyfit(path_dists, image_intensities, 1)
    # p = np.poly1d(z)
    # plt.plot(path_dists, p(path_dists), "r--")
    # plt.xlabel('Path Distance to Soma')
    # plt.ylabel('Image Intensity')
    # plt.title('Path Distance to Soma vs Image Intensity')
    # # plt.colorbar(label='Image Intensity')
    # plt.savefig("/data/kfchen/trace_ws/img_noise_test/Path_Distance_to_Soma_vs_Image_Intensity.png")
    # plt.close()

def plt_fig2():
    plt.rcParams['figure.dpi'] = 300
    human_foreground_info_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/foreground_info"
    mouse_foreground_info_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/foreground_info"

    human_files = [f for f in os.listdir(human_foreground_info_dir) if f.endswith('.npy')]
    mouse_files = [f for f in os.listdir(mouse_foreground_info_dir) if f.endswith('.npy')]

    # human_sbc, mouse_sbc = [], []
    human_result_list = {
        'foreground_median': [],
        'background_median': [],
        'foreground_mean': [],
        'background_mean': [],
        'contrast': [],
        'contrast_guo': [],
        'foreground_homogeneity_entropy': [],
        'background_homogeneity_entropy': [],
        'foreground_uniformity': [],
        'background_uniformity': [],
    }
    mouse_result_list = {
        'foreground_median': [],
        'background_median': [],
        'foreground_mean': [],
        'background_mean': [],
        'contrast': [],
        'contrast_guo': [],
        'foreground_homogeneity_entropy': [],
        'background_homogeneity_entropy': [],
        'foreground_uniformity': [],
        'background_uniformity': [],
    }


    for human_file in human_files:
        current_result = np.load(os.path.join(human_foreground_info_dir, human_file), allow_pickle=True).item()
        for key in human_result_list:
            human_result_list[key].append(current_result[key])


    for mouse_file in mouse_files:
        current_result = np.load(os.path.join(mouse_foreground_info_dir, mouse_file), allow_pickle=True).item()
        for key in mouse_result_list:
            mouse_result_list[key].append(current_result[key])


    # plot violin
    fig, ax = plt.subplots(5, 2, figsize=(8, 10))
    ax = ax.flatten()
    for i, key in enumerate(human_result_list):
        sns.violinplot(data=[human_result_list[key], mouse_result_list[key]], ax=ax[i])
        ax[i].set_xticks([0, 1])
        ax[i].set_xticklabels(['Human', 'Mouse'])
        ax[i].set_title(key)


    plt.tight_layout()
    plt.savefig("/data/kfchen/trace_ws/img_noise_test/SBC.png")
    plt.close()

def crop_swc_files():
    img_dir = "/data/kfchen/trace_ws/img_noise_test/seu1876/cropped_img_1um"
    img_files = [f for f in os.listdir(img_dir) if f.endswith('.tif')]
    def current_task(img_file):
        img = tifffile.imread(os.path.join(img_dir, img_file))
        img = img.astype(np.float32)
        img = (img - img.min()) / (img.max() - img.min()) * 255
        img = np.flip(img, axis=1)
        tifffile.imwrite(os.path.join(img_dir, img_file), img.astype('uint8'))
    # for img_file in img_files:
    #     current_task(img_file)
    joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_task)(img_file) for img_file in tqdm(img_files))

def plt_fig3():
    mask_source = "/PBshare/SEU-ALLEN/Users/KaifengChen/human_brain/img/mask"
    mask_target = "/data/kfchen/trace_ws/img_noise_test/proposed/my_great_mask"

    mask_files = [f for f in os.listdir(mask_source) if f.endswith('.tif')]
    def current_task(mask_file, mask_source, mask_target):
        id = mask_file.split('.')[0]
        xy_resolution = neuron_info_df.loc[neuron_info_df.iloc[:, 0] == int(id), 'xyæ‹æ‘„åˆ†è¾¨ç‡(*10e-3Î¼m/px)'].values[0]
        xy_resolution = float(xy_resolution) / 1000
        mask = tifffile.imread(os.path.join(mask_source, mask_file))
        mask = mask.astype(np.float32)
        mask = (mask - mask.min()) / (mask.max() - mask.min())
        mask = resize(mask, (mask.shape[0], mask.shape[1] * xy_resolution, mask.shape[2] * xy_resolution), order=1)
        mask = np.where(mask > 0.5, 255, 0)
        mask = np.flip(mask, axis=1)
        tifffile.imwrite(os.path.join(mask_target, mask_file), mask.astype('uint8'))
    # for mask_file in mask_files:
    #     current_task(mask_file)
    if(os.path.exists(mask_target) == False):
        os.makedirs(mask_target, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_task)(mask_file, mask_source, mask_target) for mask_file in tqdm(mask_files))

    # è®¡ç®—å‰æ™¯å’ŒèƒŒæ™¯çš„ç›´æ–¹å›¾
    mask_files = [f for f in os.listdir(mask_target) if f.endswith('.tif')]
    img_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_img_1um"
    temp_save_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/hist_temp"
    # os.makedirs(temp_save_dir, exist_ok=True)

    total_foreground_hist = [0 for _ in range(256)]
    total_background_hist = [0 for _ in range(256)]

    def current_task(mask_file, img_dir, mask_target, temp_save_dir):
        save_file = os.path.join(temp_save_dir, mask_file.replace('.tif', '.npy'))
        if(os.path.exists(save_file)):
            return np.load(save_file)
        img = tifffile.imread(os.path.join(img_dir, mask_file))
        mask = tifffile.imread(os.path.join(mask_target, mask_file))
        mask = np.where(mask > 0, 255, 0).astype(np.uint8)
        img = img.astype(np.float32)
        img = (img - img.min()) / (img.max() - img.min()) * 255
        img = img.astype(np.uint8)

        foreground_mask = (mask == 255)
        background_mask = (mask == 0)

        foreground_intensities = img[foreground_mask]
        background_intensities = img[background_mask]

        foreground_hist, _ = np.histogram(foreground_intensities, bins=256, range=(0, 255), density=False)
        background_hist, _ = np.histogram(background_intensities, bins=256, range=(0, 255), density=False)

        # save
        np.save(save_file, (foreground_hist, background_hist))

        return foreground_hist, background_hist

    if(os.path.exists(temp_save_dir) == False):
        os.makedirs(temp_save_dir, exist_ok=True)
        joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_task)(mask_file, img_dir, mask_target, temp_save_dir) for mask_file in tqdm(mask_files))

    for mask_file in mask_files:
        foreground_hist, background_hist = np.load(os.path.join(temp_save_dir, mask_file.replace('.tif', '.npy')))
        total_size = np.sum(foreground_hist) + np.sum(background_hist)
        foreground_hist = foreground_hist
        background_hist = background_hist
        total_foreground_hist = [a + b for a, b in zip(total_foreground_hist, foreground_hist)]
        total_background_hist = [a + b for a, b in zip(total_background_hist, background_hist)]

    print(np.sum(total_foreground_hist))
    print(np.sum(total_background_hist))
    total_foreground_hist = total_foreground_hist / np.sum(total_foreground_hist)
    total_background_hist = total_background_hist / np.sum(total_background_hist)

    set2_colors = plt.cm.get_cmap('Set2').colors

    plt.rcParams['figure.dpi'] = 300
    # plot
    plt.figure(figsize=(4, 3))
    plt.plot(total_foreground_hist, color=set2_colors[2])
    plt.plot(total_background_hist, color=set2_colors[3])
    plt.yscale('log')
    # plt.ylim(-0.0005, 0.008)
    # plt.ylim(0.0192, 0.020)
    plt.xlabel('Voxel value', fontsize=15)
    plt.ylabel('Frequency', fontsize=15)
    plt.yticks(fontsize=12)
    plt.xticks(fontsize=12)
    # å…³é—­ä¸Šè¾¹æ¡†å’Œå³è¾¹æ¡†
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)
    # plt.title('Intensity Histogram')
    plt.legend(['Foreground', 'Background'], frameon=False, fontsize=12)
    plt.tight_layout()
    plt.savefig("/data/kfchen/trace_ws/img_noise_test/Intensity_Histogram.png")
    plt.close()


def plot_fig4(bins=100):

    img_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/cropped_img_1um"
    img_files = [f for f in os.listdir(img_dir) if f.endswith('.tif')]
    # img_file = img_files[0]

    def current_task(img_file, bins, save_file):
        if(os.path.exists(save_file)):
            return
            return np.load(save_file)
        try:
            img = tifffile.imread(os.path.join(img_dir, img_file))
            fft_result = fftn(img)
            fft_shifted = fftshift(fft_result)
            energy_distribution = np.abs(fft_shifted) ** 2

            # 4. å°†èƒ½é‡åˆ†å¸ƒå±•å¹³å¹¶è®¡ç®—ç›´æ–¹å›¾
            energy_flattened = energy_distribution.flatten()
            # hist, _ = np.histogram(energy_flattened, bins=bins, range=(energy_flattened.min(), energy_flattened.max()))
            # print(hist)
            np.save(save_file, energy_flattened)
            return
            return energy_flattened
        except Exception as e:
            print(e, img_file)
            return

    temp_save_dir = "/data/kfchen/trace_ws/img_noise_test/proposed/fft_temp"
    # if(os.path.exists(temp_save_dir) == False):
    os.makedirs(temp_save_dir, exist_ok=True)
    joblib.Parallel(n_jobs=N_JOBS)(joblib.delayed(current_task)(img_file, bins, os.path.join(temp_save_dir, img_file.replace('.tif', '.npy')) ) for img_file in tqdm(img_files))

    global_min, global_max = float('inf'), float('-inf')
    print("First Pass")
    for img_file in tqdm(img_files):
        try:
            energy = np.load(os.path.join(temp_save_dir, img_file.replace('.tif', '.npy')), allow_pickle=True)
            global_min = min(global_min, energy.min())
            global_max = max(global_max, energy.max())
        except:
            pass

    print(f"Global Min: {global_min}, Global Max: {global_max}")

    # åˆå§‹åŒ–ç›´æ–¹å›¾
    total_hist = np.zeros(bins, dtype=np.int64)
    bin_edges = np.linspace(global_min, global_max, bins + 1)

    print("Second Pass")
    # ç¬¬äºŒéï¼šé€æ–‡ä»¶è®¡ç®—ç›´æ–¹å›¾å¹¶ç´¯åŠ 
    for img_file in tqdm(img_files):
        try:
            energy = np.load(os.path.join(temp_save_dir, img_file.replace('.tif', '.npy')), allow_pickle=True)
            hist, _ = np.histogram(energy, bins=bin_edges)
            total_hist += hist
        except:
            pass

    set2_colors = plt.cm.get_cmap('Set2').colors
    # æ¸…æ™°åº¦
    plt.rcParams['figure.dpi'] = 300
    plt.figure(figsize=(4, 4))
    plt.hist(total_hist, bins=bins, color='blue', alpha=0.7, log=True)
    plt.title("Histogram of Energy Distribution in Frequency Domain", fontsize=14)
    plt.xlabel("Energy", fontsize=12)
    plt.ylabel("Frequency (Log Scale)", fontsize=12)
    # plt.grid(True, linestyle="--", alpha=0.6)
    plt.savefig("/data/kfchen/trace_ws/img_noise_test/Energy_Histogram.png")
    plt.close()

    # # 5. ç»˜åˆ¶ç›´æ–¹å›¾
    # plt.figure(figsize=(10, 6))
    # plt.hist(energy_flattened, bins=bins, color='blue', alpha=0.7, log=True)
    # plt.title("Histogram of Energy Distribution in Frequency Domain", fontsize=14)
    # plt.xlabel("Energy", fontsize=12)
    # plt.ylabel("Frequency (Log Scale)", fontsize=12)
    # plt.grid(True, linestyle="--", alpha=0.6)
    # plt.show()
    # plt.close()


# ä¸»ç¨‹åº
if __name__ == '__main__':
    # crop_swc_files()
    # exit()

    # prepare_seu1876()
    # prepare_proposed()
    # prepare_seu1876_new()

    plt_fig1() # ok
    # plt_fig2()
    plt_fig3() # ok
    # plot_fig4()

