{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:  Q:\u001b[33m>>>>>>>> This is a test message\u001b[0m\n",
      "INFO:root:\u001b[1mAnother message without indent\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#设置日志记录 LLM --prompt question + response 记录\n",
    "def setup_logger():\n",
    "    \"\"\"Setup logger to always print time and level.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    logging.getLogger().setLevel(logging.INFO)  # logging.DEBUG\n",
    "\n",
    "#indent区分\n",
    "def log_w_indent(text, indent, flag ,symbol='>>'):\n",
    "    \"\"\"Log and add indent.\"\"\"\n",
    "    ind2col = {i: f\"\\x1b[{a}\" for i, a in enumerate([\n",
    "        '1m', '31m', '33m', '34m', '35m'])}\n",
    "    reset = \"\\x1b[0m\"\n",
    "\n",
    "    if indent > 0:\n",
    "        if flag == 'Question':\n",
    "            logging.info('  Q:'+\n",
    "                ind2col[indent] + (indent * 2) * symbol + ' ' + text + reset)\n",
    "        elif flag =='Response':\n",
    "            logging.info('  LLM-A:'+\n",
    "                ind2col[indent] + (indent * 2) * symbol + ' ' + text + reset)\n",
    "\n",
    "    else:\n",
    "        logging.info(ind2col[indent] + text + reset)\n",
    "\n",
    "setup_logger()\n",
    "log_w_indent('This is a test message',2,'Question')\n",
    "log_w_indent('Another message without indent', 0,'Response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置openai客户端\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "#config.json 进行配置用户openai账户 \n",
    "with open(r'neuron_seg_human\\llm_neuron_seg\\utils\\llm\\llm_config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "CLIENT = OpenAI(base_url=config['OPENAI_API_BASE'],\n",
    "                api_key=config['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:  Q:\u001b[33m>>>>>>>> Input: how to trace and restruct human neuron structure based on 3d tif images?\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:  LLM-A:\u001b[33mxxxxxxxx Output: Tracing and reconstructing human neuron structures from 3D TIFF images is a complex but well-established process in computational neuroscience. This process involves several steps, including image preprocessing, segmentation, tracing, and visualization. Here is a general workflow to help you get started:\n",
      "\n",
      "### 1. Image Preprocessing\n",
      "The initial step involves preparing the 3D TIFF images for analysis:\n",
      "- **Denoising:** Apply noise reduction techniques to improve signal-to-noise ratio.\n",
      "- **Contrast Enhancement:** Adjust contrast to enhance the visibility of neuron structures.\n",
      "- **Normalization:** Normalize the intensity values to a common scale.\n",
      "\n",
      "### 2. Segmentation\n",
      "Segmentation involves separating the neurons from the background.\n",
      "- **Thresholding:** Use thresholding techniques to differentiate neurons from the background. Automatic methods such as Otsu's thresholding or adaptive thresholding can be useful.\n",
      "- **Machine Learning:** Advanced segmentation can involve machine learning techniques like deep learning (e.g., using convolutional neural networks for image segmentation).\n",
      "\n",
      "###\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Tracing and reconstructing human neuron structures from 3D TIFF images is a complex but well-established process in computational neuroscience. This process involves several steps, including image preprocessing, segmentation, tracing, and visualization. Here is a general workflow to help you get started:\\n\\n### 1. Image Preprocessing\\nThe initial step involves preparing the 3D TIFF images for analysis:\\n- **Denoising:** Apply noise reduction techniques to improve signal-to-noise ratio.\\n- **Contrast Enhancement:** Adjust contrast to enhance the visibility of neuron structures.\\n- **Normalization:** Normalize the intensity values to a common scale.\\n\\n### 2. Segmentation\\nSegmentation involves separating the neurons from the background.\\n- **Thresholding:** Use thresholding techniques to differentiate neurons from the background. Automatic methods such as Otsu's thresholding or adaptive thresholding can be useful.\\n- **Machine Learning:** Advanced segmentation can involve machine learning techniques like deep learning (e.g., using convolutional neural networks for image segmentation).\\n\\n###\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_sentences(response):\n",
    "#     \"\"\"Extract scripts & descriptions from LLM-response.\"\"\"\n",
    "#     # Some manual exceptions for sentence extraction.\n",
    "\n",
    "#     # facts = response.replace('Ph.D.', 'PhD').replace('\\n', ' ').split('. ')\n",
    "#     # facts = [f.strip() + '.' if i < len(facts) - 1 else f.strip() for i, f in enumerate(facts)]\n",
    "#     for i in facts:\n",
    "#         print(i)\n",
    "\n",
    "# def get_sentences(response):\n",
    "#     \"\"\"Extract scripts & descriptions from LLM-response.\"\"\"\n",
    "#     # Some manual exceptions for sentence extraction.\n",
    "    \n",
    "#     # facts = response.replace('Ph.D.', 'PhD').replace('\\n', ' ').split('. ')\n",
    "#     # facts = [f.strip() + '.' if i < len(facts) - 1 else f.strip() for i, f in enumerate(facts)]\n",
    "#     for i in facts:\n",
    "#         print(i)\n",
    "\n",
    "from tenacity import (retry, wait_random_exponential)\n",
    "@retry(wait=wait_random_exponential(min=1, max=10))\n",
    "def chat_llm(prompt):\n",
    "    \"\"\"Predict with GPT-4 model.\"\"\"\n",
    "\n",
    "    if isinstance(prompt, str):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    else:\n",
    "        messages = prompt\n",
    "\n",
    "    output = CLIENT.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=messages,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    response = output.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "def llm_w_log(prompt, indent):\n",
    "    \"\"\" log inputs and outputs.\"\"\"\n",
    "    log_w_indent(f'Input: {prompt}', indent , flag='Question')\n",
    "    response = chat_llm(prompt)\n",
    "    log_w_indent(f'Output: {response}', indent, symbol='xx',flag='Response')\n",
    "    return response\n",
    "llm_w_log('how to trace and restruct human neuron structure based on 3d tif images?',2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
