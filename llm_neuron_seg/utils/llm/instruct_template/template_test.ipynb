{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###任务描述\n",
    "###分步骤描述\n",
    "###工具插件描述\n",
    "/*通过清晰地分步骤描述任务，并提供必要的工具插件信息，有效利用LLM完成具体任务，生成每一步的代码。*/\n",
    "/*确保输入结构清晰，详细描述每个步骤的要求和工具的使用方法。使得模型的输出将更加准确和实用。*/\n",
    "\n",
    "whole-> 3个stage 实现\n",
    "FOR EACH STAGE:\n",
    "  1/输入初步任务描述及可使用工具信息\n",
    "      - llm返回任务基本描述及规划步骤\n",
    "      - 人工修改步骤并确认\n",
    "  2/每一步骤逐步向llm输入并获取response代码 \n",
    "      - 代码块增量进行测试\n",
    "      - 代码在10个用例上测试通过进行步骤代码留存\n",
    "      - 不通过，返回报错 修改代码\n",
    "  3/迭代完单stage 进行批量数据测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 10:38:26 INFO       Q:\u001b[31m>>>> This is a test question\u001b[0m\n",
      "2024-07-22 10:38:26 INFO       LLM-A:\u001b[31m>>>> This is a test response\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "def clear_existing_loggers():\n",
    "    \"\"\"Clear all existing loggers to prevent conflicts.\"\"\"\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "def setup_logger(logfile_path):\n",
    "    \"\"\"Setup logger to always print time and level.\"\"\"\n",
    "    clear_existing_loggers()\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(logfile_path),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def log_w_indent(text, indent, flag, symbol='>>'):\n",
    "    \"\"\"Log and add indent.\"\"\"\n",
    "    ind2col = {i: f\"\\x1b[{a}m\" for i, a in enumerate([\n",
    "        '1', '31', '33', '34', '35'])}\n",
    "    reset = \"\\x1b[0m\"\n",
    "\n",
    "    if indent < 0 or indent >= len(ind2col):\n",
    "        raise ValueError(\"Invalid indent level\")\n",
    "\n",
    "    if indent > 0:\n",
    "        if flag == 'Question':\n",
    "            prefix = '  Q:'\n",
    "        elif flag == 'Response':\n",
    "            prefix = '  LLM-A:'\n",
    "        elif flag == 'Code':\n",
    "            prefix = '  Code script test:'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid flag\")\n",
    "\n",
    "        prefix += ind2col[indent] + (indent * 2) * symbol + ' ' + text + reset\n",
    "    else:\n",
    "        prefix = ind2col[indent] + text + reset\n",
    "\n",
    "    logging.info(prefix)\n",
    "\n",
    "setup_logger(r\"D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\log_utils\\log0720.log\")\n",
    "log_w_indent(\"This is a test question\", 1, \"Question\")\n",
    "log_w_indent(\"This is a test response\", 1, \"Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置openai客户端\n",
    "from openai import OpenAI\n",
    "# from openai.error import APIConnectionError\n",
    "#from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "#config.json 进行配置用户openai账户 \n",
    "with open(r'D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\\llm_config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "CLIENT = OpenAI(base_url=config['OPENAI_API_BASE'],\n",
    "                api_key=config['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Blocks:\n",
      "Code Block 1:\n",
      "import pandas as pd\n",
      "\n",
      "# Read CSV file\n",
      "data = pd.read_csv('input.csv')\n",
      "print(data.head())\n",
      "\n",
      "Non-Code Content:\n",
      "Here is an example of Python code:\n",
      "\n",
      "\n",
      "You can use the above code to read a CSV file.\n",
      "\n",
      "Another code snippet:\n",
      "\n",
      "python\n",
      "复制代码\n",
      "from data_cleaning_tool import clean_data\n",
      "\n",
      "# Clean data\n",
      "cleaned_data = clean_data(data)\n",
      "print(cleaned_data.head())\n",
      "Make sure to install the necessary libraries before running the code.\n"
     ]
    }
   ],
   "source": [
    "# 分离文本+提取代码块\n",
    "response = \"\"\"\n",
    "Here is an example of Python code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV file\n",
    "data = pd.read_csv('input.csv')\n",
    "print(data.head())```\n",
    "You can use the above code to read a CSV file.\n",
    "\n",
    "Another code snippet:\n",
    "\n",
    "python\n",
    "复制代码\n",
    "from data_cleaning_tool import clean_data\n",
    "\n",
    "# Clean data\n",
    "cleaned_data = clean_data(data)\n",
    "print(cleaned_data.head())\n",
    "Make sure to install the necessary libraries before running the code.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_code_blocks(response):\n",
    "    # 正则表达式匹配代码块\n",
    "    code_pattern = re.compile(r'```(?:\\w+)?\\n(.*?)```', re.DOTALL)\n",
    "    code_blocks = code_pattern.findall(response)\n",
    "    non_code_content = code_pattern.sub('', response)\n",
    "    non_code_content = non_code_content.strip()\n",
    "    \n",
    "    return code_blocks, non_code_content\n",
    "\n",
    "# 使用函数提取代码块和其他内容\n",
    "code_blocks, non_code_content = extract_code_blocks(response)\n",
    "\n",
    "print(\"Code Blocks:\")\n",
    "for i, code in enumerate(code_blocks, 1):\n",
    "    print(f\"Code Block {i}:\\n{code}\\n\")\n",
    "\n",
    "print(\"Non-Code Content:\")\n",
    "print(non_code_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed JSON content from D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\\instruct_template\\template.json:\n",
      "Parsed JSON content from D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\\code_tools.json:\n",
      "Original step_prompt_list:\n",
      "s1. Load the 3D TIF image using an appropriate library.\n",
      "s2. Preprocess the image to enhance its quality for segmentation.\n",
      "s3. Apply a segmentation algorithm to identify neuron structures.\n",
      "s4. Post-process the segmented image to refine the results.\n",
      "s5. Generate binary masks from the segmented image.\n",
      "s6. Save the binary masks as TIF files for training purposes.\n",
      "\n",
      "Key points the final script should address include:\n",
      "- Efficiently handling 3D image data.\n",
      "- Applying suitable preprocessing and segmentation techniques.\n",
      "- Refining the segmentation results to improve mask quality.\n",
      "- Ensuring the binary masks are correctly saved for training use.\n",
      "\n",
      "Please enter the modified steps. Press Enter to keep the original step.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 11:07:30 INFO       LLM-A:\u001b[33m>>>>>>>> Manual_step_list: {'s1': 'Load the 3D TIF image using an appropriate library.', 's2': 'Preprocess the image to enhance its quality for segmentation.', 's3': 'Apply a segmentation algorithm to identify neuron structures.', 's4': 'Post-process the segmented image to refine the results.', 's5': 'Generate binary masks from the segmented image.', 's6': 'Save the binary masks as TIF files for training purposes.\\n\\nKey points the final script should address include:\\n- Efficiently handling 3D image data.\\n- Applying suitable preprocessing and segmentation techniques.\\n- Refining the segmentation results to improve mask quality.\\n- Ensuring the binary masks are correctly saved for training use.'}\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLMResponse' object has no attribute 'code_script'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 222\u001b[0m\n\u001b[0;32m    220\u001b[0m llm_test \u001b[38;5;241m=\u001b[39m LLMResponse\u001b[38;5;241m.\u001b[39mload_state(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_after_get_task_step.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m llm_test\u001b[38;5;241m.\u001b[39mmanual_modify_step()\n\u001b[1;32m--> 222\u001b[0m \u001b[43mllm_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_step_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 141\u001b[0m, in \u001b[0;36mLLMResponse.get_step_code\u001b[1;34m(self, step_id)\u001b[0m\n\u001b[0;32m    139\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mini_step_description\n\u001b[0;32m    140\u001b[0m step_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_list\n\u001b[1;32m--> 141\u001b[0m pre_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode_script \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_script\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m current_step \u001b[38;5;241m=\u001b[39m step_list[step_id] \u001b[38;5;28;01mif\u001b[39;00m step_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(step_list) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LLMResponse' object has no attribute 'code_script'"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    # FoundError: 如果文件不存在。\n",
    "    # ValueError: 如果文件为空或 JSON 解析失败。\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "        if not data:\n",
    "            raise ValueError(\"The JSON file is empty.\")\n",
    "        try:\n",
    "            json_data = json.loads(data)\n",
    "            print(f\"Parsed JSON content from {file_path}:\")\n",
    "            return json_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to decode JSON from {file_path}: {e}\")\n",
    "\n",
    "template_file_path = r'D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\\instruct_template\\template.json'\n",
    "code_tools_file_path = r'D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\\code_tools.json'\n",
    "template_json = read_json_file(template_file_path)\n",
    "codetools_json = read_json_file(code_tools_file_path)\n",
    "\n",
    "class SpoofData:\n",
    "    def __getitem__(self, item):\n",
    "        return f'<{item}>'\n",
    "def md5hash(string):\n",
    "    return int(hashlib.md5(string.encode('utf-8')).hexdigest(), 16)\n",
    "#llm问答\n",
    "class LLMResponse:\n",
    "    def __init__(self,ini_task:str,code_save_dir):\n",
    "        self.ini_task_question=ini_task\n",
    "        self.ini_step_description=None\n",
    "        self.step_list = None\n",
    "        self.manual_list=None\n",
    "        # self.n_regenerate=None\n",
    "        # self.reset=reset\n",
    "        #      #迭代十次不通过 记录step_id 在reset \n",
    "        # self.reset_stages=reset_stages\n",
    "        #self.export_predict_response = defaultdict(defaultdict(list).copy)\n",
    "        self.code_script=None\n",
    "        self.code_save_dir = code_save_dir\n",
    "        \n",
    "    def save_state(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_state(filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)   \n",
    "        \n",
    "    #indent用于日志记录 stepid:步骤id  reuse:是否进行再次输入迭代\n",
    "    def llw_w_log(self, prompt, indent,stepidx, stage,reuse=False):\n",
    "        #reset.stages 重置阶段列表     拿到需要重新run的stepidx\n",
    "        if (stage in self.reset_stages) and (reset := self.reset.get(stepidx, {})):\n",
    "            if self.accept_restore_failure and not len(reset[md5hash(prompt)]):\n",
    "                logging.warning('Spoofing aborted!')\n",
    "                predict_response =llm_w_log(prompt, indent)\n",
    "            else:\n",
    "                log_w_indent(f'Spoofed Input: {prompt}', indent,flag='Question')\n",
    "                predict_response= reset[md5hash(prompt)].pop(0)\n",
    "                log_w_indent(f'Spoofed Output: {predict_response}', indent, flag='Question',symbol='xx')\n",
    "    \n",
    "        else:\n",
    "            predict_response = llm_w_log(prompt, indent)\n",
    "\n",
    "        self.export_predict_response[stepidx][md5hash(prompt)].append(predict_response)\n",
    "\n",
    "        return predict_response\n",
    "    # 生成step列表 eachstep 进行prompt修饰后 进行llm输入，获取处理代码\n",
    "\n",
    "    def get_ini_task_decription(self) -> str:\n",
    "        log_w_indent(f'Input_Question: {self.ini_task_question}', indent=0 , symbol='<<<<<<',flag='Question')\n",
    "        self.ini_task_description = chat_llm(prompt='Task:'+self.ini_task_question+template_json['get_ini_task'])\n",
    "        log_w_indent(f'Initial_task_description: {self.ini_task_description}', indent=1 , flag='Question')\n",
    "        self.save_state(\"state_after_get_ini_task_description.pkl\")\n",
    "        \n",
    "    def extract_steplist(self, text):\n",
    "        pattern = re.compile(r'(\\d+)\\.\\s*(.*?)(?=(\\d+\\.|$))', re.DOTALL)\n",
    "        matches = pattern.findall(text)\n",
    "        paragraph_dict = {f's{num}': content.strip() for num, content, _ in matches}\n",
    "        return paragraph_dict\n",
    "    \n",
    "    \n",
    "    def get_task_step(self) -> str:\n",
    "        prompt = 'Task:' + self.ini_task_question + template_json['get_step_list']\n",
    "        log_w_indent(f'Task_step_decom_prompt: {prompt}', indent=0 , flag='Question')\n",
    "        step_list = chat_llm(prompt)\n",
    "        \n",
    "        log_w_indent(f'Initial_task_step: {step_list}', indent=1 , flag='Response')\n",
    "        step_clean_list = self.extract_steplist(step_list)\n",
    "        self.step_list=step_clean_list\n",
    "        log_w_indent(f'Initial_clean_task_step: {step_clean_list}', indent=1 , flag='Response')\n",
    "        self.save_state(\"state_after_get_task_step.pkl\")\n",
    "    \n",
    "    # manual \n",
    "    def manual_modify_step(self) -> list:\n",
    "        ### human modify step_list ###\n",
    "        step_prompt_list = self.step_list\n",
    "        step_modify_list = []\n",
    "        print(\"Original step_prompt_list:\")\n",
    "        for key, step in step_prompt_list.items():\n",
    "            print(f\"{key}. {step}\")\n",
    "        print(\"\\nPlease enter the modified steps. Press Enter to keep the original step.\\n\")\n",
    "\n",
    "        # 循环获取用户输入\n",
    "        for key, step in step_prompt_list.items():\n",
    "            modified_step = input(f\"Modify the step '{step}': \")\n",
    "            if modified_step.strip():  # 如果输入不为空，去除前后的空格\n",
    "                step_modify_list.append((key, modified_step))\n",
    "            else:  \n",
    "                step_modify_list.append((key, step))\n",
    "        \n",
    "        self.manual_list = {key: step for key, step in step_modify_list}\n",
    "        log_w_indent(f'Manual_step_list: {self.manual_list}', indent=2 , flag='Response')\n",
    "        self.save_state(\"state_after_manually_modify_step.pkl\")\n",
    "    \n",
    "\n",
    "       \n",
    "    def extract_code_blocks(self,self_response):\n",
    "    # 正则表达式匹配代码块\n",
    "        code_pattern = re.compile(r'```(?:\\w+)?\\n(.*?)```', re.DOTALL)\n",
    "        code_blocks = code_pattern.findall(response)\n",
    "        non_code_content = code_pattern.sub('', response)\n",
    "        non_code_content = non_code_content.strip()\n",
    "        self.code_script = code_blocks\n",
    "       \n",
    "    \n",
    "        return code_blocks, non_code_content\n",
    "    \n",
    "    def get_step_code(self, step_id):\n",
    "    # stepid 以 s1/s2...\n",
    "        task = self.ini_step_description\n",
    "        step_list = self.manual_list\n",
    "        pre_code = self.code_script if self.code_script is not None else \"\"\n",
    "        current_step = step_list[step_id] if step_id < len(step_list) else None\n",
    "    \n",
    "        if current_step is None:\n",
    "            raise ValueError(f\"Step ID {step_id} is out of range in the step list.\")\n",
    "    \n",
    "        code_tools = codetools_json\n",
    "    # step_code 要改 json无法\n",
    "        prompt = (template_json['get_step_code'] + \n",
    "              f'{task}\\nHere is the step-by-step plan: {step_list}\\n'\n",
    "              f'Here is the script of pre_steps: {pre_code}\\n'\n",
    "              f'Here is the current step: {current_step}\\n'\n",
    "              f'Please prioritize using the following code tools and libraries if they fit the step requirements: {code_tools}\\n'\n",
    "              'Provide only the whole code script and return the script only.')\n",
    "    \n",
    "        log_w_indent(f'{step_id}_code_question: {prompt}', indent=0, flag='Question')\n",
    "    \n",
    "        try:\n",
    "            step_response = chat_llm(prompt)\n",
    "            step_code, _ = extract_code_blocks(self, step_response)\n",
    "            self.code_script = step_code\n",
    "            log_w_indent(f'{step_id}_code_script: {self.code_script}', indent=2, flag='Code')\n",
    "            return step_response\n",
    "        except Exception as e:\n",
    "            log_w_indent(f'Error in getting step code: {str(e)}', indent=2, flag='Error')\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "    # def get_all_prompts_for_log(self):\n",
    "    #     # Spoof data to log prompting format.\n",
    "    #     data = SpoofData()\n",
    "    #     prompts = dict(\n",
    "    #         gen_ini_task_decription=self.gen_ini_task_decription(data),\n",
    "    #         task_step_list= self.gen_task_step(data),\n",
    "    #         manual_modify_list = self.manual_modify_step(data),\n",
    "    #         step_description=  self.extract_code_blocks(data),\n",
    "    #         # 步骤额外信息也需记录\n",
    "    #         # step_response =self.get_step_code(step_response)),\n",
    "    #         # step_code,step_code_description =extract_code_blocks(data)\n",
    "    #         )\n",
    "    #     #logger记录所有\n",
    "    \n",
    "    #     return prompts\n",
    "\n",
    "    def run_script(self, input_data, step_id, output_suffix):\n",
    "        code = self.code_script\n",
    "        script_dir = self.code_save_dir\n",
    "        file_path = os.path.join(script_dir, f'{step_id}_script.py')\n",
    "        output_file_path = os.path.join(script_dir, f'{step_id}_output.{output_suffix}')\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"w\") as file:\n",
    "                file.write(code)\n",
    "        except Exception as e:\n",
    "            return f\"Error writing to file: {e}\"\n",
    "\n",
    "        cmd_command = f\"python {file_path} {input_data}\"\n",
    "        try:\n",
    "            result = subprocess.run(cmd_command, shell=True, capture_output=True, text=True)\n",
    "            result.check_returncode()  # 检查命令是否成功运行\n",
    "            logging.info(f\"Code script generated successfully!!{file_path}:{result.stdout}\")\n",
    "            return result.stdout\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            logging.info(f\"Error running script: {e.stderr.strip()}\")\n",
    "            return e.stderr.strip()\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Unexpected error: {str(e)}\")\n",
    "            return str(e)\n",
    "        \n",
    "    # def pass_metric(self):\n",
    "\n",
    "\n",
    "\n",
    "ques = 'How to generate training masks for tracing neuron structures from 3D TIF images of human brain neurons??'\n",
    "code_save_dir = r\"D:\\GXQ\\human_seg\\neuron_seg_human\\llm_neuron_seg\\utils\\llm\"\n",
    "# llm_test = LLMResponse(ini_task=ques,code_save_dir=code_save_dir)\n",
    "# llm_test.get_ini_task_decription()\n",
    "# llm_test.get_task_step()\n",
    "llm_test = LLMResponse.load_state(\"state_after_get_task_step.pkl\")\n",
    "llm_test.manual_modify_step()\n",
    "llm_test.get_step_code(step_id='s1')\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Visualize Neuron Structure**\n",
      "   - **Description**: Visualize the neuron structures in 3D to confirm accuracy and for further analysis.\n",
      "   - **Tools**: `matplotlib` (3D plotting), `neuroglancer`, or other 3D visualization tools.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_paragraphs(text):\n",
    "    # 使用正则表达式匹配以数字加句点开头的段落\n",
    "    pattern = re.compile(r'(\\d+)\\.\\s*(.*?)(?=(\\d+\\.|$))', re.DOTALL)\n",
    "    matches = pattern.findall(text)\n",
    "    \n",
    "    # 创建字典，数字作为key，段落内容作为value\n",
    "    paragraph_dict = {f's{num}': content.strip() for num, content, _ in matches}\n",
    "    \n",
    "    return paragraph_dict\n",
    "\n",
    "# 示例文本\n",
    "text = \"\"\"\n",
    "1. **Install Required Libraries**\n",
    "   - **Description**: Set up the Python environment and install the necessary libraries. Common libraries for handling 3D image data and processing neurons include `numpy`, `scipy`, `skimage`, `tifffile`, `neuroglancer`, and `matplotlib`.\n",
    "   - **Tools**: `pip` for installation.\n",
    "\n",
    "2. **Load 3D TIF Image**\n",
    "   - **Description**: Load the 3D TIF image into memory for processing. Utilize libraries like `tifffile` to handle the image file.\n",
    "   - **Tools**: `tifffile` for reading the TIF file.\n",
    "\n",
    "3. **Preprocess Image**\n",
    "   - **Description**: Preprocess the image to enhance features of the neurons. This could involve normalization, denoising, and contrast enhancement.\n",
    "   - **Tools**: `skimage` for preprocessing functions such as `filters` and `exposure`.\n",
    "\n",
    "4. **Segment Neurons**\n",
    "   - **Description**: Apply segmentation algorithms to distinguish neurons from the background. Common methods include thresholding, edge detection, and morphological operations.\n",
    "   - **Tools**: `skimage` for segmentation tasks with algorithms like `threshold_otsu`, `canny`, and `morphology`.\n",
    "\n",
    "5. **Skeletonize Neurons**\n",
    "   - **Description**: Reduce the segmented neurons to a skeletal representation to simplify the structure while retaining meaningful connectivity.\n",
    "   - **Tools**: `skimage.morphology.skeletonize_3d`.\n",
    "\n",
    "6. **Trace Neuron Paths**\n",
    "   - **Description**: Develop a tracing algorithm to follow along the skeleton of the neurons, potentially creating a graph representation of the structure.\n",
    "   - **Tools**: Custom Python functions leveraging `numpy` for array manipulation.\n",
    "\n",
    "7. **Visualize Neuron Structure**\n",
    "   - **Description**: Visualize the neuron structures in 3D to confirm accuracy and for further analysis.\n",
    "   - **Tools**: `matplotlib` (3D plotting), `neuroglancer`, or other 3D visualization tools.\n",
    "\n",
    "8. **Extract and Save Neuron Data**\n",
    "   - **Description**: Extract meaningful data from the neuron structures, such as branch points and connection pathways. Save this data in a structured format (e.g., CSV, JSON).\n",
    "   - **Tools**: `numpy`, `pandas` for data manipulation and saving.\n",
    "\"\"\"\n",
    "\n",
    "# 提取段落并保存到字典中\n",
    "paragraphs = extract_paragraphs(text)\n",
    "print(paragraphs['s7'])\n",
    "# 打印字典\n",
    "# for key, value in paragraphs.items():\n",
    "#     print(f'{key}: {value}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# 配置api日志记录\n",
    "logging.basicConfig(level=logging.WARNING, filename='chat_llm.log', filemode='a',\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "from tenacity import (retry, wait_random_exponential)\n",
    "@retry(wait=wait_random_exponential(min=1, max=10))\n",
    "\n",
    "\n",
    "def chat_llm(prompt,temperature=0.5):\n",
    "    \"\"\"Predict with GPT-4 model.\"\"\"\n",
    "\n",
    "    if isinstance(prompt, str):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    else:\n",
    "        messages = prompt\n",
    "\n",
    "    try:\n",
    "        output = CLIENT.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=messages,\n",
    "            temperature =temperature\n",
    "        )\n",
    "        response = output.choices[0].message.content\n",
    "        return response\n",
    "    except openai.error.APIConnectionError as e:\n",
    "        # 记录日志警告及错误信息\n",
    "        logging.warning(f\"APIConnectionError occurred: {e}\")\n",
    "        return \"An external error occurred while trying to connect to the API. Please try again later.\"\n",
    "\n",
    "\n",
    "def main(prompt):\n",
    "    \"\"\" log inputs and outputs.\"\"\"\n",
    "    log_w_indent(f'Input: {prompt}', indent=1 , flag='Question')\n",
    "    response = chat_llm(prompt)\n",
    "    ##处理response\n",
    "    log_w_indent(f'Output: {response}', indent=2, symbol='xx',flag='Response')\n",
    "    return response\n",
    "# main('how to trace and restruct human neuron structure based on 3d tif images?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
